{
 "cells": [
  {
   "source": [
    "# BGT zadanie 4\n",
    "## Autors\n",
    "- Paweł Benkowski\n",
    "- Stanisław Lutkiewicz\"\n",
    "### Task\n",
    "Downloads Nietzsche and freud books count words in it.  \n",
    "Finds top 10 words and 3 top nouns  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: PyPDF2 in /opt/conda/lib/python3.8/site-packages (1.26.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (2.25.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests) (2020.11.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: bs4 in /opt/conda/lib/python3.8/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.8/site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.8/site-packages (from nltk) (2020.11.13)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from nltk) (4.54.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install PyPDF2\n",
    "!{sys.executable} -m pip install requests\n",
    "!{sys.executable} -m pip install bs4\n",
    "!{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/jovyan/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkFiles\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from operator import add\n",
    "import os\n",
    "import requests\n",
    "import PyPDF2\n",
    "import re\n",
    "import nltk\n",
    "import timeit\n",
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books_urls(url):\n",
    "    urlsWithName = []\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        arr = a[\"href\"].split(\".\")\n",
    "        if arr[-1] == \"pdf\":\n",
    "            urlsWithName.append((\"http:\" +a[\"href\"],a.string))\n",
    "    return urlsWithName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books_and_create_folder(urls, target):\n",
    "    if not os.path.isdir(target):\n",
    "        os.makedirs(target)\n",
    "    for url in urls:\n",
    "        file = Path(target,url[1] + \".pdf\")\n",
    "        if not file.exists ():\n",
    "            response = requests.get(url[0])\n",
    "            with open(Path(target, url[1] + \".pdf\"), \"wb+\") as f:\n",
    "                f.write(response.content)\n",
    "        else:\n",
    "            print(\"File already exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_text_from_pdf(name):\n",
    "    file = Path(name + \".txt\")\n",
    "    if not file.exists ():\n",
    "        fileReader = PyPDF2.PdfFileReader(name)\n",
    "        with open(Path(name + \".txt\"), \"a+\") as f:\n",
    "            for page in fileReader.pages:\n",
    "                f.write(page.extractText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_noun(word : str) -> bool:\n",
    "    if \"s\" == word or \"i\" == word:\n",
    "        return False\n",
    "    partOfSpeech = nltk.pos_tag([word])\n",
    "    if \"NN\" == partOfSpeech[0][1]:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_text_files(textFiles):\n",
    "    if len(textFiles) == 1 :\n",
    "        return textFiles[0].name\n",
    "    with open(textFiles[0],'a') as toAppend:\n",
    "        for txt in textFiles[1::]:\n",
    "            with open(txt) as fromAppend:\n",
    "                toAppend.write(fromAppend.read())\n",
    "            os.remove(txt)\n",
    "    return textFiles[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local\", \"first app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n"
     ]
    }
   ],
   "source": [
    "folderNamesWithUrls = [('freud',\"https://holybooks.com/sigmund-freud-the-complete-works/\"),\\\n",
    "    ('nitsche',\"https://holybooks.com/the-complete-works-of-friedrich-nietzsche-in-english-as-pdf/\")]\n",
    "files = []\n",
    "for fnwu in folderNamesWithUrls:\n",
    "    urls = get_books_urls(fnwu[1])\n",
    "    get_books_and_create_folder(urls, fnwu[0])\n",
    "    pdfFiles = list(Path(fnwu[0]).glob('*.pdf'))\n",
    "    for pdf in pdfFiles:\n",
    "        save_text_from_pdf(os.path.join(fnwu[0], pdf.name))\n",
    "    textFileName = compose_text_files(list(Path(fnwu[0]).glob('*.txt')))\n",
    "    files.append(sc.textFile(os.path.join(fnwu[0], textFileName)).cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "freud/Sigmund Freud – The Complete Works.pdf.txt MapPartitionsRDD[5] at textFile at NativeMethodAccessorImpl.java:0\n",
      "total word 2068906\n",
      "most common [('the', 142371), ('of', 94924), ('to', 60988), ('in', 50950), ('a', 48808), ('and', 46208), ('that', 33805), ('is', 30431), ('it', 27788), ('which', 22649)]\n",
      "top nouns [('dream', 6115), ('analysis', 3584), ('time', 3456)]\n",
      "time spend 17.891764156986028\n",
      "------------------------------------------------------------------------------------------\n",
      "nitsche/The complete works of Friedrich Nietzsche VOL XVI.pdf.txt MapPartitionsRDD[7] at textFile at NativeMethodAccessorImpl.java:0\n",
      "total word 1304489\n",
      "most common [('the', 84034), ('of', 59756), ('and', 44130), ('to', 36902), ('a', 26105), ('in', 24907), ('is', 21215), ('that', 16802), ('it', 14520), ('as', 13386)]\n",
      "top nouns [('man', 4285), ('life', 2701), ('power', 2536)]\n",
      "time spend 17.786092587019084\n",
      "------------------------------------------------------------------------------------------\n",
      "total time spend 35.678389096981846\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "for file in files:\n",
    "    startIn = timeit.default_timer()\n",
    "    print(file)\n",
    "    lowerCaseText = file.map(lambda x: x.lower())\n",
    "    words = lowerCaseText.map(lambda x : re.findall(r\"\\b[^\\d\\W]+\\b\", x)).flatMap(lambda x: x)\n",
    "   \n",
    "    wordsForCounting = words.map(lambda x: (x,1))\n",
    "    countedNouns = wordsForCounting.reduceByKey(add).filter(lambda x: is_noun(x[0])).collect()\n",
    "    \n",
    "    kNouns = Counter(dict(countedNouns))\n",
    "    kWords = Counter(words.collect())\n",
    "    \n",
    "    print(f\"total word {words.count()}\")\n",
    "    print(f\"most common {kWords.most_common(10)}\")\n",
    "    print(f\"top nouns {kNouns.most_common(3)}\")\n",
    "    print(f\"time spend {timeit.default_timer() - startIn}\")\n",
    "    print(30*\"----\")\n",
    "print(f\"total time spend {timeit.default_timer()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}