{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /opt/conda/lib/python3.8/site-packages (1.26.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (2.25.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests) (2020.11.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: bs4 in /opt/conda/lib/python3.8/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.8/site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from nltk) (4.54.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.8/site-packages (from nltk) (2020.11.13)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install PyPDF2\n",
    "!{sys.executable} -m pip install requests\n",
    "!{sys.executable} -m pip install bs4\n",
    "!{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkFiles\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from operator import add\n",
    "import os\n",
    "import requests\n",
    "import PyPDF2\n",
    "import re\n",
    "import nltk\n",
    "import timeit\n",
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books_urls(url):\n",
    "    urlsWithName = []\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        arr = a[\"href\"].split(\".\")\n",
    "        if arr[-1] == \"pdf\":\n",
    "            urlsWithName.append((\"http:\" +a[\"href\"],a.string))\n",
    "    return urlsWithName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books_and_create_folder(urls, target):\n",
    "    if not os.path.isdir(target):\n",
    "        os.makedirs(target)\n",
    "    for url in urls:\n",
    "        file = Path(target,url[1] + \".pdf\")\n",
    "        if not file.exists ():\n",
    "            response = requests.get(url[0])\n",
    "            with open(Path(target, a.string + \".pdf\"), \"wb+\") as f:\n",
    "                f.write(response.content)\n",
    "        else:\n",
    "            print (\"File already exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_text_from_pdf(name):\n",
    "    file = Path(name + \".txt\")\n",
    "    if not file.exists ():\n",
    "        fileReader = PyPDF2.PdfFileReader(name)\n",
    "        with open(Path(name + \".txt\"), \"a+\") as f:\n",
    "            for page in fileReader.pages:\n",
    "                f.write(page.extractText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n"
     ]
    }
   ],
   "source": [
    "folderName = 'freud'\n",
    "urls = get_books_urls(\"https://holybooks.com/sigmund-freud-the-complete-works/\")\n",
    "get_books_and_create_folder(urls, folderName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path(folderName)\n",
    "pdfFiles = list(p.glob('*.pdf'))\n",
    "for b_p in pdfFiles:\n",
    "    save_text_from_pdf(os.path.join(folderName, b_p.name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local\", \"first app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path(folderName)\n",
    "allTextFiles = list(p.glob('*.txt'))\n",
    "files = []\n",
    "for b_p in allTextFiles:\n",
    "    files.append(sc.textFile(os.path.join(folderName, b_p.name)).cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_noun(word : str) -> bool:\n",
    "    if \"s\" == word or \"i\" == word:\n",
    "        return False\n",
    "    partOfSpeech = nltk.pos_tag([word])\n",
    "    if \"NN\" == partOfSpeech[0][1]:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2068906\n",
      "[('the', 142371), ('of', 94924), ('to', 60988), ('in', 50950), ('a', 48808), ('and', 46208), ('that', 33805), ('is', 30431), ('it', 27788), ('which', 22649)]\n",
      "[('dream', 6115), ('analysis', 3584), ('time', 3456)]\n",
      "15.255547217999265\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "for file in files:\n",
    "    lowerCaseText = file.map(lambda x: x.lower())\n",
    "    words = lowerCaseText.map(lambda x : re.findall(r\"\\b[^\\d\\W]+\\b\", x)).flatMap(lambda x: x)\n",
    "   \n",
    "    wordsForCounting = words.map(lambda x: (x,1))\n",
    "    countedNouns = wordsForCounting.reduceByKey(add).filter(lambda x: is_noun(x[0])).collect()\n",
    "    \n",
    "    kNouns = Counter(dict(countedNouns))\n",
    "    kWords = Counter(words.collect())\n",
    "    \n",
    "    print(words.count())\n",
    "    print(kWords.most_common(10))\n",
    "    print(kNouns.most_common(3))\n",
    "end = timeit.default_timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
