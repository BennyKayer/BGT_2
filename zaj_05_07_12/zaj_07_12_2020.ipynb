{
 "cells": [
  {
   "source": [
    "# BGT zadanie 5\n",
    "## Autors\n",
    "- Paweł Benkowski\n",
    "- Stanisław Lutkiewicz\"\n",
    "### Task\n",
    "Downloads Nietzsche and freud books count group of words in it(tiny,small,medium,big).  \n",
    "Match language by analyzing character frequency  \n",
    "Covid cases in India region   "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: PyPDF2 in /opt/conda/lib/python3.8/site-packages (1.26.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (2.25.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests) (2020.11.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: bs4 in /opt/conda/lib/python3.8/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.8/site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from nltk) (4.54.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.8/site-packages (from nltk) (2020.11.13)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install PyPDF2\n",
    "!{sys.executable} -m pip install requests\n",
    "!{sys.executable} -m pip install bs4\n",
    "!{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/jovyan/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkFiles\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from operator import add\n",
    "import os\n",
    "import requests\n",
    "import PyPDF2\n",
    "import re\n",
    "import nltk\n",
    "import timeit\n",
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books_urls(url):\n",
    "    urlsWithName = []\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        arr = a[\"href\"].split(\".\")\n",
    "        if arr[-1] == \"pdf\":\n",
    "            urlsWithName.append((\"http:\" +a[\"href\"],a.string))\n",
    "    return urlsWithName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books_and_create_folder(urls, target):\n",
    "    if not os.path.isdir(target):\n",
    "        os.makedirs(target)\n",
    "    for url in urls:\n",
    "        file = Path(target,url[1] + \".pdf\")\n",
    "        if not file.exists():\n",
    "            response = requests.get(url[0])\n",
    "            with open(Path(target, url[1] + \".pdf\"), \"wb+\") as f:\n",
    "                f.write(response.content)\n",
    "        else:\n",
    "            print(\"File already exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_text_from_pdf(name):\n",
    "    file = Path(name + \".txt\")\n",
    "    if not file.exists():\n",
    "        fileReader = PyPDF2.PdfFileReader(name)\n",
    "        with open(Path(name + \".txt\"), \"a+\") as f:\n",
    "            for page in fileReader.pages:\n",
    "                f.write(page.extractText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_noun(word : str) -> bool:\n",
    "    if \"s\" == word or \"i\" == word:\n",
    "        return False\n",
    "    partOfSpeech = nltk.pos_tag([word])\n",
    "    if \"NN\" == partOfSpeech[0][1]:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_text_files(textFiles):\n",
    "    if len(textFiles) == 1 :\n",
    "        return textFiles[0].name\n",
    "    with open(textFiles[0],'a') as toAppend:\n",
    "        for txt in textFiles[1::]:\n",
    "            with open(txt) as fromAppend:\n",
    "                toAppend.write(fromAppend.read())\n",
    "            os.remove(txt)\n",
    "    return textFiles[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local\", \"first app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    }
   ],
   "source": [
    "folderNamesWithUrls = [('freud',\"https://holybooks.com/sigmund-freud-the-complete-works/\"),\\\n",
    "    ('nitsche',\"https://holybooks.com/the-complete-works-of-friedrich-nietzsche-in-english-as-pdf/\")]\n",
    "files = []\n",
    "for fnwu in folderNamesWithUrls:\n",
    "    urls = get_books_urls(fnwu[1])\n",
    "    get_books_and_create_folder(urls, fnwu[0])\n",
    "    pdfFiles = list(Path(fnwu[0]).glob('*.pdf'))\n",
    "    for pdf in pdfFiles:\n",
    "        save_text_from_pdf(os.path.join(fnwu[0], pdf.name))\n",
    "    textFileName = compose_text_files(list(Path(fnwu[0]).glob('*.txt')))\n",
    "    files.append(sc.textFile(os.path.join(fnwu[0], textFileName)).cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_letters_and_print_ratio(lettersRdd):\n",
    "    lettersForCounting = lowerCaseLetters.map(lambda x: (x,1))\n",
    "    countedLetters =  lettersForCounting.reduceByKey(add).collect()\n",
    "    kLetters = Counter(dict(countedLetters))\n",
    "    mostCommonLetters = kLetters.most_common(3)\n",
    "    allLetters = lowerCaseLetters.count()\n",
    "    print(f\"top letters {mostCommonLetters}\")\n",
    "    print(f\"total letters {allLetters}\")\n",
    "    for mcl in mostCommonLetters:\n",
    "        print(f\"{mcl[0]} : {(mcl[1]/allLetters)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<bound method RDD.name of freud/Sigmund Freud – The Complete Works.pdf.txt MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0>\n",
      "['f', 'r', 'e', 'u', 'd', 'c', 'o', 'm', 'p', 'l']\n",
      "top letters [('e', 1204065), ('t', 931463), ('i', 759718)]\n",
      "total letters 9572627\n",
      "e : 12.578208677722428%\n",
      "t : 9.730484641258872%\n",
      "i : 7.936358535645439%\n",
      "total word 2068906\n",
      "most common [('the', 142371), ('of', 94924), ('to', 60988), ('in', 50950), ('a', 48808), ('and', 46208), ('that', 33805), ('is', 30431), ('it', 27788), ('which', 22649)]\n",
      "top nouns [('dream', 6115), ('analysis', 3584), ('time', 3456)]\n",
      "time spend 37.55681641600677\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "<bound method RDD.name of nitsche/The complete works of Friedrich Nietzsche VOL XVI.pdf.txt MapPartitionsRDD[3] at textFile at NativeMethodAccessorImpl.java:0>\n",
      "['t', 'h', 'e', 'c', 'o', 'm', 'p', 'l', 'e', 't']\n",
      "top letters [('e', 1464448), ('t', 1124984), ('i', 920888)]\n",
      "total letters 11809052\n",
      "e : 12.401063184411417%\n",
      "t : 9.526454790782529%\n",
      "i : 7.798153484293236%\n",
      "total word 2608978\n",
      "most common [('the', 168068), ('of', 119512), ('and', 88260), ('to', 73804), ('a', 52210), ('in', 49814), ('is', 42430), ('that', 33604), ('it', 29040), ('as', 26772)]\n",
      "top nouns [('man', 8570), ('life', 5402), ('power', 5072)]\n",
      "time spend 51.464592447009636\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "total time spend 89.02236430699122\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "for file in files: # paralize -> foreach\n",
    "    startIn = timeit.default_timer()\n",
    "    print(file.name)\n",
    "    lowerCaseText = file.map(lambda x: x.lower())\n",
    "    lowerCaseLetters = lowerCaseText.flatMap(lambda x: re.findall(r\"[a-zA-Z]\", x))\n",
    "    count_letters_and_print_ratio(lowerCaseLetters)\n",
    "\n",
    "    words = lowerCaseText.flatMap(lambda x : re.findall(r\"\\b[^\\d\\W]+\\b\", x))\n",
    "   \n",
    "    wordsForCounting = words.map(lambda x: (x,1))\n",
    "    countedNouns = wordsForCounting.reduceByKey(add).filter(lambda x: is_noun(x[0])).collect()\n",
    "    \n",
    "    kNouns = Counter(dict(countedNouns))\n",
    "    kWords = Counter(words.collect())\n",
    "    \n",
    "    print(f\"total word {words.count()}\")\n",
    "    print(f\"most common {kWords.most_common(10)}\")\n",
    "    print(f\"top nouns {kNouns.most_common(3)}\")\n",
    "    print(f\"time spend {timeit.default_timer() - startIn}\")\n",
    "    print(30*\"----\")\n",
    "print(f\"total time spend {timeit.default_timer()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}