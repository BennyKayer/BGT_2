{
 "cells": [
  {
   "source": [
    "# BGT zadanie 6\n",
    "## Autors\n",
    "- Paweł Benkowski\n",
    "- Stanisław Lutkiewicz\"\n",
    "### Task\n",
    "Read movies and their ratings.  \n",
    "Get recommendation for particular user.  \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (2.25.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests) (2020.11.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkFiles\n",
    "from pyspark.sql import SparkSession, functions\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkSession = SparkSession.builder.master(\"local\").appName(\"BGT 6\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{0: 'Paweł Czapiewski', 1: 'Ola Piętka', 2: 'Robert Deyk', 3: 'Jaromir Daruk', 4: 'Benedykt Kościński', 5: 'Paweł Benkowski', 6: 'Filip Mikołajek', 7: 'Jakub Kulaszewicz', 8: 'Robert Mielewczyk', 9: 'Stanisław Lutkiewicz', 10: 'Wiktor Maj'}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Read and format data for further calculation\n",
    "'''\n",
    "fileName = \"BigData - Filmy.csv\"\n",
    "userRatings = {}\n",
    "titles = {}\n",
    "combinedUsersTitlesRating = []\n",
    "numberToTitle = {}\n",
    "numberToUser = {}\n",
    "with open(fileName) as csvFile:\n",
    "    csvReader = csv.reader(csvFile,delimiter=\";\")\n",
    "    for row in csvReader:\n",
    "        # print(row)\n",
    "        user = row[0]\n",
    "        filmy = row[1::2]\n",
    "        oceny = row[2::2]\n",
    "        for film in set(filmy):\n",
    "            if film not in titles.keys():\n",
    "                titles[film]=len(titles)    #encode titles\n",
    "        userRatings[user] = dict(zip(filmy, oceny))\n",
    "users = dict(zip(userRatings.keys(),list(range(len(userRatings.keys())))))\n",
    "\n",
    "# combine movies and users\n",
    "for name,movies in userRatings.items():\n",
    "    numberToUser[users[name]] = name # for later decoding\n",
    "    for title,rating in movies.items():\n",
    "        numberToTitle[titles[title]] = title # for later decoding\n",
    "        combination = (users[name],titles[title],float(rating))\n",
    "        combinedUsersTitlesRating.append(combination)\n",
    "\n",
    "print(numberToUser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#module-pyspark.ml.recommendation\n",
    "create model adn get recommendation\n",
    "'''\n",
    "df = sparkSession.createDataFrame(combinedUsersTitlesRating, [\"user\", \"item\", \"rating\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "als = ALS(rank=10, seed=0)\n",
    "als.setMaxIter(5)\n",
    "als.getMaxIter()\n",
    "als.setRegParam(0.1)\n",
    "als.getRegParam()\n",
    "als.clear(als.regParam)\n",
    "model = als.fit(df)\n",
    "model.getBlockSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "userId = 0\n",
    "\n",
    "userTitles = [x[1] for x in combinedUsersTitlesRating if x[0] == userId]\n",
    "titlesWithoutSelectedUser = [(userId,x) for x in titles.values() if x not in userTitles]\n",
    "\n",
    "titlesWithoutSelectedUserDf = sparkSession.createDataFrame(titlesWithoutSelectedUser, [\"user\", \"item\"])\n",
    "predictions = sorted(model.transform(titlesWithoutSelectedUserDf).collect(), key=lambda r: r[2],reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Interstellar\nMarsjanin\nPlayer One\nMindhunter\nChernobyl\n"
     ]
    }
   ],
   "source": [
    "# print predictions\n",
    "counter = 0\n",
    "for row in predictions[:5]:\n",
    "    print(numberToTitle[row[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}